help(party)
library("party", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
library("partykit", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
help(party)
### data ###
## artificial WeatherPlay data
data("WeatherPlay", package = "partykit")
str(WeatherPlay)
### splits ###
## split in overcast, humidity, and windy
sp_o <- partysplit(1L, index = 1:3)
sp_h <- partysplit(3L, breaks = 75)
sp_w <- partysplit(4L, index = 1:2)
## query labels
character_split(sp_o)
### nodes ###
## set up partynode structure
pn <- partynode(1L, split = sp_o, kids = list(
partynode(2L, split = sp_h, kids = list(
partynode(3L, info = "yes"),
partynode(4L, info = "no"))),
partynode(5L, info = "yes"),
partynode(6L, split = sp_w, kids = list(
partynode(7L, info = "yes"),
partynode(8L, info = "no")))))
pn
### tree ###
## party: associate recursive partynode structure with data
py <- party(pn, WeatherPlay)
py
plot(py)
plot(WeatherPlay)
install.packages("twitteR")
library("twitteR", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
install.packages("ROAuth")
library("ROAuth", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
install.packages("plyr")
install.packages("dplyr")
install.packages("stringr")
install.packages("ggplot2")
library(twitteR)
library(ROAuth)
library(plyr)
library(dplyr)
library(stringr)
library(ggplot2)
download.file(url='http://curl.haxx.se/ca/cacert.pem', destfile='cacert.pem')
reqURL <- 'https://api.twitter.com/oauth/request_token'
accessURL <- 'https://api.twitter.com/oauth/access_token'
authURL <- 'https://api.twitter.com/oauth/authorize'
consumerKey <- '''
;
.
''
consumerKey <- 'janardhanbonu'
consumerSecret <- 'Janas01p'
Cred <- OAuthFactory$new(consumerKey=consumerKey, consumerSecret=consumerSecret, requestURL=reqURL, accessURL=accessURL, authURL=authURL)
Cred$handshake(cainfo = system.file('CurlSSL', 'cacert.pem', package = 'RCurl'))
Cred$handshake(cainfo = system.file('CurlSSL', 'cacert.pem', package = 'RCurl'))
save(Cred, file='twitter authentication.Rdata')
load('twitter authentication.Rdata')
registerTwitterOAuth(Cred)
consumerKey <- '7nuVr7YuXX2r8nu9igAApbHnw'
consumerSecret <- 'nTAN5gXz59H7JI7emA0QkWvxFTzR1GrKLbeqiihGjefQX5Pk5e'
Cred <- OAuthFactory$new(consumerKey=consumerKey, consumerSecret=consumerSecret, requestURL=reqURL, accessURL=accessURL, authURL=authURL)
Cred$handshake(cainfo = system.file('CurlSSL', 'cacert.pem', package = 'RCurl'))
save(Cred, file='twitter authentication.Rdata')
load('twitter authentication.Rdata')
registerTwitterOAuth(Cred)
setup_twitter_oauth('7nuVr7YuXX2r8nu9igAApbHnw', 'nTAN5gXz59H7JI7emA0QkWvxFTzR1GrKLbeqiihGjefQX5Pk5e','134792481-LkKjG1nZVq0h5M9Qa6I8ftLH1os7Dyfti2t2rmie', 'eXc7plKzxHSniOJqAE3JtBLih8E9Qz7u2z6ohJS5ZDNYE', credentials_file=NULL)
setup_twitter_oauth('7nuVr7YuXX2r8nu9igAApbHnw', 'nTAN5gXz59H7JI7emA0QkWvxFTzR1GrKLbeqiihGjefQX5Pk5e','134792481-LkKjG1nZVq0h5M9Qa6I8ftLH1os7Dyfti2t2rmie', 'eXc7plKzxHSniOJqAE3JtBLih8E9Qz7u2z6ohJS5ZDNYE', NULL)
setup_twitter_oauth('7nuVr7YuXX2r8nu9igAApbHnw', 'nTAN5gXz59H7JI7emA0QkWvxFTzR1GrKLbeqiihGjefQX5Pk5e','134792481-LkKjG1nZVq0h5M9Qa6I8ftLH1os7Dyfti2t2rmie', 'eXc7plKzxHSniOJqAE3JtBLih8E9Qz7u2z6ohJS5ZDNYE', "NULL"")
;
''
.
,
''
""
setup_twitter_oauth('7nuVr7YuXX2r8nu9igAApbHnw', 'nTAN5gXz59H7JI7emA0QkWvxFTzR1GrKLbeqiihGjefQX5Pk5e','134792481-LkKjG1nZVq0h5M9Qa6I8ftLH1os7Dyfti2t2rmie', 'eXc7plKzxHSniOJqAE3JtBLih8E9Qz7u2z6ohJS5ZDNYE', 'NULL')
setup_twitter_oauth('7nuVr7YuXX2r8nu9igAApbHnw', 'nTAN5gXz59H7JI7emA0QkWvxFTzR1GrKLbeqiihGjefQX5Pk5e','134792481-LkKjG1nZVq0h5M9Qa6I8ftLH1os7Dyfti2t2rmie', 'eXc7plKzxHSniOJqAE3JtBLih8E9Qz7u2z6ohJS5ZDNYE')
setwd("~/OneDrive/MUM/datamining/twitter")
narendramodi.list <- searchTwitter('narendramodi', cainfo='cacert.pem', n=1500)
df <- twListToDF(narendramodi.list)
df <- df[, order(names(df))]
df$created <- strftime(df$created, '%Y-%m-%d')
if (file.exists(paste(searchterm, 'modi.csv'))==FALSE) write.csv(df, file=paste(searchterm, 'modi.csv'), row.names=F)
narendramodi.list <- searchTwitter('#narendramodi', n=1500, cainfo='cacert.pem')
download.file(url='http://curl.haxx.se/ca/cacert.pem', destfile='cacert.pem')
narendramodi.list <- searchTwitter('#narendramodi', n=1500, cainfo='cacert.pem')
narendramodi.list <- searchTwitter('#narendramodi', n=1500, cainfo='cacert.pem')
user <- getUser("#narendramodi")
user <- getUser("narendramodi")
narendramodi.list <- searchTwitter('narendramodi', n=1500, cainfo='cacert.pem')
user
user$location
narendramodi.list <- searchTwitter('narendramodi', n=1500)
df <- twListToDF(narendramodi.list)
df <- df[, order(names(df))]
df$created <- strftime(df$created, '%Y-%m-%d')
if (file.exists(paste('narendramodi', 'modi.csv'))==FALSE) write.csv(df, file=paste(searchterm, 'modi.csv'), row.names=F)
if (file.exists(paste('narendramodi', 'modi.csv'))==FALSE) write.csv(df, file=paste('narendramodi', 'modi.csv'), row.names=F)
savehistory("~/OneDrive/MUM/datamining/twitter/twitter.Rhistory")
hu.liu.pos = scan('/Users/janardhanbonu/OneDrive/MUM/datamining/twitter/positive-words.txt', what='character', comment.char=';')
hu.liu.neg = scan('/Users/janardhanbonu/OneDrive/MUM/datamining/twitter/negative-words.txt', what='character', comment.char=';')
pos.words = c(hu.liu.pos, 'upgrade')
neg.words = c(hu.liu.neg, 'wtf', 'wait', 'waiting', 'epicfail', 'mechanical')
savehistory("~/OneDrive/MUM/datamining/twitter/twitter.Rhistory")
modidataset <- read.csv('/Users/janardhanbonu/OneDrive/MUM/datamining/twitter/narendramodi.csv')
modidataset$text <- as.factor(modidataset$text)
scores <- score.sentiment(modidataset$text, pos.words, neg.words, .progress='text')
score.sentiment = function(sentences, pos.words, neg.words, .progress='none')
{
require(plyr)
require(stringr)
# we got a vector of sentences. plyr will handle a list or a vector as an "l" for us
# we want a simple array of scores back, so we use "l" + "a" + "ply" = laply:
scores = laply(sentences, function(sentence, pos.words, neg.words) {
# clean up sentences with R's regex-driven global substitute, gsub():
sentence = gsub('[[:punct:]]', '', sentence)
sentence = gsub('[[:cntrl:]]', '', sentence)
sentence = gsub('\\d+', '', sentence)
# and convert to lower case:
sentence = tolower(sentence)
# split into words. str_split is in the stringr package
word.list = str_split(sentence, '\\s+')
# sometimes a list() is one level of hierarchy too much
words = unlist(word.list)
# compare our words to the dictionaries of positive & negative terms
pos.matches = match(words, pos.words)
neg.matches = match(words, neg.words)
# match() returns the position of the matched term or NA
# we just want a TRUE/FALSE:
pos.matches = !is.na(pos.matches)
neg.matches = !is.na(neg.matches)
# and conveniently enough, TRUE/FALSE will be treated as 1/0 by sum():
score = sum(pos.matches) - sum(neg.matches)
return(score)
}, pos.words, neg.words, .progress=.progress )
scores.df = data.frame(score=scores, text=sentences)
return(scores.df)
}
modidataset <- read.csv('/Users/janardhanbonu/OneDrive/MUM/datamining/twitter/narendramodi.csv')
modidataset$text <- as.factor(modidataset$text)
scores <- score.sentiment(modidataset$text, pos.words, neg.words, .progress='text')
write.csv(scores, file=paste('narendramodi', '_scores.csv'), row.names=TRUE)
stat <- scores
stat$created <- stack$created
stat$created <- as.Date(stat$created)
view(scores)
library("RColorBrewer", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
view(scores)
library(RColorBrewer)
view(scores)
View(scores)
View(scores)
hist(scores, xlab="score tweets")
hist(scores, xlab="Scoreof tweets", col-brewer.pal(9,"Set 3"))
hist(scores$score, xlab="Scoreof tweets", col-brewer.pal(9,"Set 3"))
hist(scores$score, xlab="Scoreof tweets", col-brewer.pal(9,"Set3"))
hist(scores$score, xlab="Scoreof tweets")
hist(scores$score, xlab="Scoreof tweets", col-brewer.pal(9,3))
hist(scores$score, xlab="Scoreof tweets", col-brewer.pal(9,'Set3'))
hist(scores$score, xlab="Scoreof tweets", col-brewer.pal(9,true))
savehistory("~/OneDrive/MUM/datamining/twitter/twitter1.Rhistory")
hist(scores$score, xlab="Scoreof tweets", col-brewer.pal(9,true))
hist(scores$score, xlab="Scoreof tweets", col-brewer.pal(9,"Set3"))
hist(scores$score, xlab="Scoreof tweets", col-brewer.pal(9,"set3"))
hist(scores$score, xlab="Scoreof tweets", col-brewer.pal(9,"Set 3"))
hist(scores$score, xlab="Scoreof tweets", col-brewer.pal(9,"Set3"))
hist(scores$score, xlab="Scoreof tweets", brewer.pal(9,"Set3"))
hist(scores$score, xlab="Scoreof tweets", col-brewer.pal(9,"Set1"))
hist(scores$score, xlab="Scoreof tweets", col-brewer.pal(1,"Set1"))
hist(scores$score, xlab="Scoreof tweets", col-brewer.pal(3,"Set1"))
savehistory("~/OneDrive/MUM/datamining/twitter/twitter1.Rhistory")
stat$created
scores$created
modidataset$created
stat
stat$created <- modidataset$created
stat$created <- as.Date(stat$created)
stat <- mutate(stat, tweet=ifelse(stat$score > 0, 'positive', ifelse(stat$score < 0, 'negative', 'neutral')))
by.tweet <- group_by(stat, tweet, created)
by.tweet <- summarise(by.tweet, number=n())
write.csv(by.tweet, file=paste(searchterm, '_opin.csv'), row.names=TRUE)
by.tweet <- group_by(stat, tweet, created)
by.tweet <- summarise(by.tweet, number=n())
write.csv(by.tweet, file=paste('narendramodi', '_opin.csv'), row.names=TRUE)
ggplot(by.tweet, aes(created, number)) + geom_line(aes(group=tweet, color=tweet), size=2) +
geom_point(aes(group=tweet, color=tweet), size=4) +
theme(text = element_text(size=18), axis.text.x = element_text(angle=90, vjust=1)) + ggtitle(searchterm)
ggsave(file=paste(searchterm, '_plot.jpeg'))
qplot(scores$score, xlab="xlab")
ggplot(by.tweet, aes(created, number)) + geom_line(aes(group=tweet, color=tweet), size=2) +
geom_point(aes(group=tweet, color=tweet), size=4) +
theme(text = element_text(size=18), axis.text.x = element_text(angle=90, vjust=1)) +
#stat_summary(fun.y = 'sum', fun.ymin='sum', fun.ymax='sum', colour = 'yellow', size=2, geom = 'line') +
ggtitle('naredhramodi')
stat <- mutate(stat, tweet=ifelse(stat$score > 0, 'positive', ifelse(stat$score < 0, 'negative', 'neutral')))
by.tweet <- group_by(stat, tweet, created)
by.tweet <- summarise(by.tweet, number=n())
write.csv(by.tweet, file=paste('narendramodi', '_opin.csv'), row.names=TRUE)
ggplot(by.tweet, aes(created, number)) + geom_line(aes(group=tweet, color=tweet), size=2) +
geom_point(aes(group=tweet, color=tweet), size=4) +
theme(text = element_text(size=18), axis.text.x = element_text(angle=90, vjust=1)) +
#stat_summary(fun.y = 'sum', fun.ymin='sum', fun.ymax='sum', colour = 'yellow', size=2, geom = 'line') +
ggtitle('narend stat <- scores
stat$created <- stack$created
stat$created <- as.Date(stat$created)
stat <- mutate(stat, tweet=ifelse(stat$score > 0, 'positive', ifelse(stat$score < 0, 'negative', 'neutral')))
by.tweet <- group_by(stat, tweet, created)
by.tweet <- summarise(by.tweet, number=n())
write.csv(by.tweet, file=paste('narendramodi, '_opin.csv'), row.names=TRUE)')
savehistory("~/OneDrive/MUM/datamining/twitter/twitter2.Rhistory")
qplot(scores$score, xlab="Narendra Modi's Score")
library(tm)
install.packages("tm")
library("tm", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
library(tm)
library(wordcloud)
install.packages("wordcloud")
library(wordcloud)
modisource = "/Users/janardhanbonu/OneDrive/MUM/datamining/twitter/modi/"
words = Corpus(DirSource(modisource))
words
words = Corpus(DirSource("/Users/janardhanbonu/OneDrive/MUM/datamining/twitter/modi/narendramodi.csv"))
words = Corpus(DirSource("/Users/janardhanbonu/OneDrive/MUM/datamining/twitter/modi/"))
words
inspect(words)
savehistory("~/OneDrive/MUM/datamining/twitter/twitter2.Rhistory")
words <- tm_map(words, stripWhitespace)
words <- tm_map(words, tolower)
words <- tm_map(words, removeWords, stopwords(“english”))
words <- tm_map(words, stemDocument)
words <- tm_map(words, stripWhitespace)
words <- tm_map(words, tolower)
words <- tm_map(words, removeWords, stopwords("english"))
words <- tm_map(words, stemDocument)
install.packages("SnowballC")
library(SnowballC)
words <- tm_map(words, stripWhitespace)
words <- tm_map(words, tolower)
words <- tm_map(words, removeWords, stopwords("english"))
words <- tm_map(words, stemDocument)
hist(scores, xlab="score tweets")
hist(scores$score, xlab="Scoreof tweets", col-brewer.pal(9,'Set3'))
hist(scores$score, xlab="Scoreof tweets", col-brewer.pal(9,"Set3"))
hist(scores$score, xlab="Scoreof tweets", col=brewer.pal(9,"Set3"))
hist(scores$score, xlab="Sentiment Score of  Narendra Modi's tweets", col=brewer.pal(9,"Set3"))
wordcloud(ds, scale=c(5,0.5), max.words=100, random.order=FALSE, rot.per=0.35, use.r.layout=FALSE, colors=brewer.pal(8, “Dark2″))
wordcloud(ds, scale=c(5,0.5), max.words=100, random.order=FALSE, rot.per=0.35, use.r.layout=FALSE, colors=brewer.pal(8, "Dark2"))
wordcloud(words, scale=c(5,0.5), max.words=100, random.order=FALSE, rot.per=0.35, use.r.layout=FALSE, colors=brewer.pal(8, "Dark2"))
tdm <- TermDocumentMatrix(words)m1 <- as.matrix(tdm)v1<- sort(rowSums(m1), decreasing=TRUE)d1 <- data.frame(word=names(v1), freq=v1)wordcloud(d1$word,d1$freq,col=brewer.pal(8,”Set2), min.freq=”1”)
tdm <- TermDocumentMatrix(words)m1 <- as.matrix(tdm)v1<- sort(rowSums(m1), decreasing=TRUE)d1 <- data.frame(word=names(v1), freq=v1)wordcloud(d1$word,d1$freq,col=brewer.pal(8,”Set2), min.freq=”1”)
tdm <- TermDocumentMatrix(words)
words1 <- tm_map(words, stripWhitespace)
words1 <- tm_map(words, tolower)
words1 <- tm_map(words, removeWords, stopwords("english"))
words1 <- tm_map(words, stemDocument)
tdm <- TermDocumentMatrix(words1)
m1 <- as.matrix(tdm)
v1<- sort(rowSums(m1), decreasing=TRUE)
d1 <- data.frame(word=names(v1), freq=v1)
wordcloud(d1$word,d1$freq,col=brewer.pal(8,”Set2), min.freq=”1”)
inspect(words)
savehistory("~/OneDrive/MUM/datamining/twitter/twitter2.Rhistory")
